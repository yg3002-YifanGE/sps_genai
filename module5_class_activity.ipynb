{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7f0bdc9",
   "metadata": {},
   "source": [
    "# Module 5 Class Activity â€” Add VAE to Helper Library\n",
    "\n",
    "This notebook trains a Variational Autoencoder (VAE) using your `helper_lib` package and visualizes generated samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7c578b",
   "metadata": {},
   "source": [
    "## 0. Environment Check\n",
    "Install missing packages if needed (run only if they are not already installed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a29e85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed, uncomment:\n",
    "# !pip install torch torchvision matplotlib\n",
    "import torch, torchvision, matplotlib\n",
    "print('Torch:', torch.__version__)\n",
    "print('CUDA available:', torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d937ebb",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c354721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_lib.data_loader import get_data_loader\n",
    "from helper_lib.trainer import train_model, train_vae_model\n",
    "from helper_lib.model import get_model\n",
    "from helper_lib.generator import generate_samples\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b2b13f",
   "metadata": {},
   "source": [
    "## 2. Data Loaders\n",
    "Load MNIST (or your course default dataset) via `helper_lib.data_loader`. Change batch size as you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf90c913",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_data_loader(root='data', batch_size=128, train=True)\n",
    "test_loader  = get_data_loader(root='data', batch_size=128, train=False)\n",
    "len(train_loader), len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cc2a76",
   "metadata": {},
   "source": [
    "## 3. Build VAE Model\n",
    "We construct the VAE via `get_model(\"VAE\", latent_dim=20)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b997ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "vae = get_model(\"VAE\", latent_dim=20)\n",
    "optimizer = optim.Adam(vae.parameters(), lr=1e-3)\n",
    "vae\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4cd7dc",
   "metadata": {},
   "source": [
    "## 4. Train VAE\n",
    "`train_vae_model` implements BCE+KLD loss internally. Adjust `epochs` and `beta` if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aeac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = train_vae_model(vae, train_loader, optimizer, device=device, epochs=5, beta=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49cb349",
   "metadata": {},
   "source": [
    "## 5. Generate Samples\n",
    "Sample random latent vectors, decode, and visualize a grid of generated images. Also save to file if you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3ec299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display grid\n",
    "generate_samples(vae, device=device, num_samples=16, seed=42)\n",
    "\n",
    "# Optionally save:\n",
    "# generate_samples(vae, device=device, num_samples=16, seed=42, save_path='vae_samples.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55514918",
   "metadata": {},
   "source": [
    "## 6. (Optional) Reconstruction vs Original\n",
    "Visualize how well the model reconstructs input images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdf2d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "vae.eval()\n",
    "images, _ = next(iter(test_loader))\n",
    "images = images.to(device)\n",
    "with torch.no_grad():\n",
    "    recon, mu, logvar = vae(images)\n",
    "\n",
    "# show first 8 originals and reconstructions\n",
    "n = 8\n",
    "fig, axes = plt.subplots(2, n, figsize=(n*1.5, 3))\n",
    "for i in range(n):\n",
    "    axes[0, i].imshow(images[i,0].detach().cpu(), cmap='gray')\n",
    "    axes[0, i].axis('off')\n",
    "    axes[1, i].imshow(recon[i,0].detach().cpu().clamp(0,1), cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "axes[0,0].set_title('Originals')\n",
    "axes[1,0].set_title('Reconstructions')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}